---
title: "R Notebook"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

https://pastebin.com/TiERhrpg
https://en.wikipedia.org/wiki/Last_meal
https://henryhargreaves.com/No-Seconds

```{r, libs}
library(tidyverse)
library(httr)
library(stringdist)
library(rvest)    
library(stringr)
library(tidytext)
library(igraph)
library(ggraph)
data(stop_words)
```

```{r include=FALSE}
theme_custom <- function() {
  theme_gray() +
    theme(
      panel.grid.minor.y = element_line(color = NA),
      panel.grid.major.y = element_line(color = "gray95"),
      panel.grid.minor.x = element_line(color = NA),
      panel.grid.major.x = element_line(color = "gray95"),
      panel.background = element_rect(fill = NA),
      plot.background = element_rect(
        fill = NA,
        color = "gray95",
        size = 10
      ),
      plot.margin = unit(c(1, 1, 1, 1), "cm"),
      axis.title = element_text(color = "gray30"),
      axis.ticks = element_line(color = NA),
      strip.background = element_rect(fill = "gray95"),
      strip.text = element_text(
        color = "gray30",
        size = 11,
        face = "bold"
      ),
      plot.title = element_text(color = "gray30",
                                face = "bold"),
      plot.subtitle = element_text(size = 10,
                                   color = "gray30"),
      text = element_text(family = "Helvetica")
    )
}

theme_set(theme_custom())
```


```{r scraping}
# set the base url
base.url <- "https://en.wikipedia.org/wiki/Last_meal"
response <- read_html(base.url)

# scrape the table
tables <- html_nodes(x = response,
                         xpath = '//table[contains(@class, "sortable")]') %>% 
  html_children()

# pull the US table
US.table <- tables[4] %>%
  html_children() %>%
  html_text() %>%
  matrix(ncol = 1, byrow = TRUE) %>%
  as_tibble() %>% 
  separate(
    V1,
    into = c("Name", "Crime", "State", "Year", "Method.of.Dispatch", "Requested.Meal", "tmp", "tmp2", "tmp3", "tmp4", "tmp5"),
    sep = "\n"
  )
```

```{r, manual fixes}
# fix row 35
US.table[35, "Crime"] <- US.table[35, "State"]
US.table[35, "State"] <- US.table[35, "Method.of.Dispatch"]
US.table[35, "Year"] <- US.table[35, "tmp"]
US.table[35, "Method.of.Dispatch"] <- US.table[35, "tmp3"]
US.table[35, "Requested.Meal"] <- US.table[35, "tmp5"]
US.table[35,]

# remove extra columns and first row
US.table <- select(US.table, -contains("tmp"))
US.table <- US.table[-1,]

# standardize the method of dispatch descriptions
US.table$Method.of.Dispatch <- str_to_sentence(US.table$Method.of.Dispatch)
table(US.table$Method.of.Dispatch)

US.table$Method.of.Dispatch <- recode(
  US.table$Method.of.Dispatch,
  "Electric chair" = "Electrocution",
  "Electrocution, photographed in the electric chair" = "Electrocution",
  "Hanged, last person executed in public in the us" = "Hanging",
  "Lethal injection. Clemency appeal based on his being too overweight for lethal injection drugs to work on him properly" = "Lethal injection"
)

# convert Year to numeric
US.table$Year <- as.numeric(US.table$Year)

US.table %>% View
```

We need to remove observations of inmates that didn't request a meal or received a meal that was not requested. We're interested in what people *wanted* as their last meal.

```{r, exclude names}
excl.names <- c("David Mason", "Odell Barnes", "Philip Workman")
US.table <- US.table[!(US.table$Name %in% excl.names),]
```

EDA

```{r, EDA}
# summary bar plots
table(US.table$Crime) %>% barplot()
table(US.table$State) %>% barplot()
table(US.table$Year) %>% barplot()
table(US.table$Method.of.Dispatch) %>% barplot()

# plot of methods over time
US.table %>% 
  group_by(Year, Method.of.Dispatch) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(x = Year, y = n, group = Method.of.Dispatch,
             fill = Method.of.Dispatch)) +
  geom_col(position = 'dodge') +
  labs(y = 'Count')
```

Text
```{r}
parsed.words <- US.table %>%
  select(Name, Requested.Meal) %>% 
  unnest_tokens(output = word, input = Requested.Meal) %>% 
  anti_join(stop_words, by = "word")

# top words
parsed.words %>% 
  group_by(word) %>%
  summarize(n = n()) %>%
  arrange(desc(n)) %>% 
  top_n(n = 15, wt = n) %>% 
  ggplot(aes(x = reorder(word, -n), y = n)) +
  geom_col() +
  labs(title = "Most common words within last meal requests",
       x = "Word",
       y = "Count")

```


Foodbase

Download foodbase from here: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6827550/

Pull out the ingredients which will act as comparison for our foods


```{r}
foodbase <- read_xml('Foodbase/FoodBase_curated.xml')
# xml_structure(foodbase, file = "xmlstructure.txt")
food.words <- xml_find_all(foodbase, xpath = "/collection/document/annotation/text") %>% xml_text()

# xml_children()
# xml_siblings()
# xml_parent()
# xml_find_one()
# xml_find_all()
# xml_path()
# xml_text()
# xml_attrs()
# xml_attr()
# xml_name()

parsed.words %>% 
  group_by(word) %>%
  summarize(n = n()) %>% 
  arrange(desc(n)) %>% 
  mutate(match = word %in% food.words) %>% View


# top food words
parsed.words %>% 
  filter(word %in% food.words) %>% 
  group_by(word) %>%
  summarize(n = n()) %>%
  arrange(desc(n)) %>% 
  top_n(n = 15, wt = n) %>% 
  ggplot(aes(x = reorder(word, -n), y = n)) +
  geom_col() +
  labs(title = "Most common words within last meal requests",
       x = "Word",
       y = "Count")

```

# repeat with ngrams

```{r}
parsed.ngrams <- US.table %>%
  select(Name, Requested.Meal) %>% 
  unnest_tokens(output = word, input = Requested.Meal, token = "skip_ngrams") %>% 
  anti_join(stop_words, by = "word") %>% 
  filter(word %in% food.words)

parsed.ngrams %>% 
  group_by(word) %>%
  summarize(n = n()) %>%
  arrange(desc(n)) %>%
  top_n(n = 15, wt = n) %>% 
  ggplot(aes(x = reorder(word, n), y = n, fill = n)) +
  geom_col() +
  scale_fill_gradient(low = "#0b2919", high = "#2b7551") +
  labs(title = "Most common words within last meal requests",
       x = "Word",
       y = "Count") +
  coord_flip()

```

